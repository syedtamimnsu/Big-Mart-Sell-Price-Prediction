# -*- coding: utf-8 -*-
"""Big Mart Sales Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k3kHCZXypSoOe3AZPo1cJ56MkF-M27ws

Import dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""Dataa collection and processing"""

#loading dataset in pandas data frame
big_mart_data = pd.read_csv('/content/Train.csv')

big_mart_data.head( )

big_mart_data.tail( )

big_mart_data.shape

#informatio about dataset
big_mart_data.info(  )

#check number of null value
big_mart_data.isnull().sum()

"""Handling Missing Values

for 'Item_weight' column = Mean --> average

for 'Outlet_Size' column = Mode --> more repeated value

"""

#mean value of "Item_weight" column
big_mart_data['Item_Weight'].mean()

#replace missing values of "item_weight " column as mean value
big_mart_data['Item_Weight'].fillna(big_mart_data['Item_Weight'].mean(), inplace=True)

#big_mart_data = big_mart_data.dropna(subset=['Item_Weight'])

big_mart_data.shape

#check number of null value
big_mart_data.isnull().sum()

"""There are a positeve correlation between "Outlet_Size" and "Outlet_Type" columns.



"""

#mode of "Outlet_size" column
big_mart_data['Outlet_Size'].mode()

#filling the messing values in "outlet_size" column with mode
#depend on "outlet_type" column find mode of "outlet_size"
mode_of_outlet_size = big_mart_data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))

print(mode_of_outlet_size)

miss_values = big_mart_data['Outlet_Size'].isnull()

print(miss_values)

#where found miss_value = falses ,there repalce as mode vale depend on outlet_type column values
big_mart_data.loc[miss_values, 'Outlet_Size'] = big_mart_data.loc[miss_values, 'Outlet_Type'].apply(lambda x: mode_of_outlet_size[x])

#check number of null value
big_mart_data.isnull().sum()

#describe the dataset
big_mart_data.describe()

"""Nuemerical features"""

#Item_Weight describe
plt.figure(figsize=(6,6))
sns.displot(big_mart_data['Item_Weight'])
plt.show()

#Item_Visibility describe
plt.figure(figsize=(6,6))
sns.displot(big_mart_data['Item_Visibility'])
plt.show()



"""Data Pre-Processing"""

big_mart_data.head()

#check values of column
big_mart_data['Item_Fat_Content'].value_counts()

# Low Fat, LF, low fat => all of them define Low Fat
#Regular, Ragular reg => Regurar
#Replace them as Law Fat and Ragular
big_mart_data.replace({'Item_Fat_Content': {'low fat':'Low Fat', 'LF':'Low Fat', 'reg':'Regular', 'Ragular': 'Regular'}}, inplace=True)

#check values of column
big_mart_data['Item_Fat_Content'].value_counts()

"""Label Encode

Replaced a unique value for all catagorical values
"""

big_mart_data.head()

encoder = LabelEncoder()

big_mart_data['Item_Identifier'] = encoder.fit_transform(big_mart_data['Item_Identifier'])
big_mart_data['Item_Fat_Content'] = encoder.fit_transform(big_mart_data['Item_Fat_Content'])
big_mart_data['Item_Type'] = encoder.fit_transform(big_mart_data['Item_Type'])
big_mart_data['Outlet_Identifier'] = encoder.fit_transform(big_mart_data['Outlet_Identifier'])
big_mart_data['Outlet_Size'] = encoder.fit_transform(big_mart_data['Outlet_Size'])
big_mart_data['Outlet_Location_Type'] = encoder.fit_transform(big_mart_data['Outlet_Location_Type'])
big_mart_data['Outlet_Type'] = encoder.fit_transform(big_mart_data['Outlet_Type'])

big_mart_data.head()

"""Splittng features and target"""

x = big_mart_data.drop(columns=['Item_Outlet_Sales'], axis=1)
y = big_mart_data['Item_Outlet_Sales']

print(x)

print(y)

"""Splitting data into training and testing data"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)

print(x.shape, x_train.shape, x_test.shape)

"""Machine Learning Model Training

XGBoost Regressor
"""

regressor = XGBRegressor()

regressor.fit(x_train, y_train)

#prediction on training data
training_data_prediction = regressor.predict(x_train)

#R squared value
r2_train = metrics.r2_score(y_train, training_data_prediction)

print('Trsining data R Square value: ', r2_train)

#prediction on testing data
testing_data_prediction = regressor.predict(x_test)

#R squared value
r2_test = metrics.r2_score(y_test, testing_data_prediction)

print('testing data R Square value: ', r2_test)

